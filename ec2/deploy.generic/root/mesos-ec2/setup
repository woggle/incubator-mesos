#!/bin/bash

# Make sure we are in the mesos-ec2 directory
cd /root/mesos-ec2

# Set hostname based on EC2 private DNS name, so that it is set correctly
# even if the instance is restarted with a different private DNS name
PRIVATE_DNS=`wget -q -O - http://instance-data.ec2.internal/latest/meta-data/local-hostname`
hostname $PRIVATE_DNS
echo $PRIVATE_DNS > /etc/hostname
export HOSTNAME=$PRIVATE_DNS  # Fix the bash built-in hostname variable too

echo "Setting up Mesos master on `hostname`..."

# Read command-line arguments
OS_NAME=$1
SWAP_MB=$2

MASTERS_FILE="masters"
MASTERS=`cat $MASTERS_FILE`
NUM_MASTERS=`cat $MASTERS_FILE | wc -l`
OTHER_MASTERS=`cat $MASTERS_FILE | sed '1d'`
SLAVES=`cat slaves`
ZOOS=`cat zoo`

if [[ $ZOOS = *NONE* ]]; then
  NUM_ZOOS=0
  ZOOS=""
else
  NUM_ZOOS=`cat zoo | wc -l`
fi

# Scripts that get used for/while running Mesos.
SCRIPTS="copy-dir
         create-swap
         mesos-daemon
         redeploy-mesos
         setup-slave              
         ssh-no-keychecking
         start-hypertable
         start-mesos
         stop-hypertable
         stop-mesos
         "

EPHEMERAL_HDFS=/root/ephemeral-hdfs
PERSISTENT_HDFS=/root/persistent-hdfs

SSH_OPTS="-o StrictHostKeyChecking=no -o ConnectTimeout=5"

if [[ `tty` == "not a tty" ]] ; then
    echo "Expecting a tty or pty! (use the ssh -t option)."
    exit 1
fi

echo "Setting executable permissions on scripts..."
for s in $SCRIPTS; do chmod u+x $s; done

echo "Running setup-slave on master to mount filesystems, etc..."
./setup-slave $SWAP_MB

echo "SSH'ing to master machine(s) to approve key(s)..."
for master in $MASTERS; do
  echo $master
  ssh $SSH_OPTS $master echo -n &
  sleep 0.3
done
ssh $SSH_OPTS localhost echo -n &
ssh $SSH_OPTS `hostname` echo -n &
wait

if [[ $NUM_ZOOS != 0 ]] ; then
  echo "SSH'ing to ZooKeeper server(s) to approve keys..."
  zid=1
  for zoo in $ZOO; do
    echo $zoo
    ssh $SSH_OPTS $zoo echo -n \; mkdir -p /tmp/zookeeper \; echo $zid \> /tmp/zookeeper/myid &
    zid=$(($zid+1))
    sleep 0.3
  done
fi

# Try to SSH to each cluster node to approve their key. Since some nodes may
# be slow in starting, we retry failed slaves up to 3 times.
TODO="$SLAVES $ZOO $OTHER_MASTERS" # List of nodes to try (initially all)
TRIES="0"                          # Number of times we've tried so far
echo "SSH'ing to other cluster nodes to approve keys..."
while [ "e$TODO" != "e" ] && [ $TRIES -lt 4 ] ; do
  NEW_TODO=
  for slave in $TODO; do
    echo $slave
    ssh $SSH_OPTS $slave echo -n
    if [ $? != 0 ] ; then
        NEW_TODO="$NEW_TODO $slave"
    fi
  done
  TRIES=$[$TRIES + 1]
  if [ "e$NEW_TODO" != "e" ] && [ $TRIES -lt 4 ] ; then
      sleep 15
      TODO="$NEW_TODO"
      echo "Re-attempting SSH to cluster nodes to approve keys..."
  else
      break;
  fi
done

echo "RSYNC'ing /root/mesos-ec2 to other cluster nodes..."
for node in $SLAVES $ZOO $OTHER_MASTERS; do
  echo $node
  rsync -e "ssh $SSH_OPTS" -az /root/mesos-ec2 $node:/root &
  scp $SSH_OPTS ~/.ssh/id_rsa $node:.ssh &
  sleep 0.3
done
wait

echo "Running slave setup script on other cluster nodes..."
for node in $SLAVES $ZOO $OTHER_MASTERS; do
  echo $node
  ssh -t $SSH_OPTS root@$node "mesos-ec2/setup-slave $SWAP_MB" & sleep 0.3
done
wait

echo "RSYNC'ing HDFS config files to other cluster nodes..."
for node in $SLAVES $ZOO $OTHER_MASTERS; do
  echo $node
  rsync -e "ssh $SSH_OPTS" -az $EPHEMERAL_HDFS/conf \
                               $node:$EPHEMERAL_HDFS &
  rsync -e "ssh $SSH_OPTS" -az $PERSISTENT_HDFS/conf \
                               $node:$PERSISTENT_HDFS &
  sleep 0.3
done
wait

echo "Setting up Hadoop framework config files..."
cp hadoop-framework-conf/* /root/hadoop/conf

echo "Setting up NFS..."
if [ ! -e /nfs ] ; then
  mkdir -p /mnt/nfs
  rm -fr /nfs
  ln -s /mnt/nfs /nfs
fi
if ! grep -e '^/nfs ' /etc/exports; then
  echo "/nfs    10.0.0.0/8(ro,async,no_subtree_check)" >> /etc/exports
fi
service rpcbind start
if [ -e /etc/init.d/nfs-common ]; then
  service nfs-common start
fi
if [ -e /etc/init.d/nfs-kernel-server ]; then
  service nfs-kernel-server start
else
  service nfs start
fi
# Unexport and re-export everything in /etc/exports because, if we are
# restarting a stopped EC2 instance, we might have had an entry for /nfs in
# /etc/exports before we created /mnt/nfs.
exportfs -ua
exportfs -a

echo "Mounting NFS on slaves..."
for slave in $SLAVES; do
  echo $slave
  ssh -t $SSH_OPTS root@$slave "mkdir -p /nfs; service rpcbind start; service nfs start || service nfs-common start; mount $HOSTNAME:/nfs /nfs" & sleep 0.3
done
wait

echo "Formatting ephemeral HDFS namenode..."
$EPHEMERAL_HDFS/bin/hadoop namenode -format

echo "Starting ephemeral HDFS..."
if [ -x $EPHEMERAL_HDFS/sbin/start-dfs.sh ]; then
  $EPHEMERAL_HDFS/sbin/start-dfs.sh
else
  $EPHEMERAL_HDFS/bin/start-dfs.sh
fi

if grep -q /vol /proc/mounts; then
  if [[ ! -e /vol/persistent-hdfs/dfs/name ]] ; then
    echo "Formatting persistent HDFS namenode..."
    $PERSISTENT_HDFS/bin/hadoop namenode -format
  fi

  echo "Starting persistent HDFS..."
  if [ -x $PERSISTENT_HDFS/sbin/start-dfs.sh ]; then
    $PERSISTENT_HDFS/sbin/start-dfs.sh
  else
    $PERSISTENT_HDFS/bin/start-dfs.sh
  fi
fi

sleep 1

ln -s /root/mesos-ec2/masters /root/mesos/var/mesos/deploy/masters
ln -s /root/mesos-ec2/slaves /root/mesos/var/mesos/deploy/slaves

if [[ $NUM_ZOOS != 0 ]]; then
  echo "Starting ZooKeeper quorum..."
  for zoo in $ZOOS; do
    ssh $SSH_OPTS $zoo "/root/zookeeper/bin/zkServer.sh start </dev/null >/dev/null" & sleep 0.1
  done
  wait
  sleep 5
fi

echo "Stopping any existing Mesos cluster..."
/root/mesos/sbin/mesos-stop-cluster.sh
sleep 2

echo "Starting Mesos cluster..."
/root/mesos/sbin/mesos-start-cluster.sh
